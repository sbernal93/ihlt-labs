{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package movie_reviews to\n",
      "[nltk_data]     /home/santiago/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/movie_reviews.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('movie_reviews')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** man and girl **\n",
      "Least Common Subsumers: ['adult']\n",
      "Path Similarity: 0.25\n",
      "Leacock-Chodorow Similarity: 2.2512917986064953\n",
      "Wu-Palmer Similarity: 0.631578947368421\n",
      "Lin Similarity: 0.7135111237276783\n",
      "\n",
      "** man and male_child **\n",
      "Least Common Subsumers: ['male']\n",
      "Path Similarity: 0.3333333333333333\n",
      "Leacock-Chodorow Similarity: 2.538973871058276\n",
      "Wu-Palmer Similarity: 0.6666666666666666\n",
      "Lin Similarity: 0.7294717876200584\n",
      "\n",
      "** man and woman **\n",
      "Least Common Subsumers: ['adult']\n",
      "Path Similarity: 0.3333333333333333\n",
      "Leacock-Chodorow Similarity: 2.538973871058276\n",
      "Wu-Palmer Similarity: 0.6666666666666666\n",
      "Lin Similarity: 0.7870841372982784\n",
      "\n",
      "** swim and walk **\n",
      "Least Common Subsumers: ['travel']\n",
      "Path Similarity: 0.3333333333333333\n",
      "Leacock-Chodorow Similarity: 2.159484249353372\n",
      "Wu-Palmer Similarity: 0.3333333333333333\n",
      "Lin Similarity: 0.4910052007916556\n",
      "\n",
      "** girl and male_child **\n",
      "Least Common Subsumers: ['person']\n",
      "Path Similarity: 0.16666666666666666\n",
      "Leacock-Chodorow Similarity: 1.845826690498331\n",
      "Wu-Palmer Similarity: 0.631578947368421\n",
      "Lin Similarity: 0.2927280671561499\n",
      "\n",
      "** girl and woman **\n",
      "Least Common Subsumers: ['woman']\n",
      "Path Similarity: 0.5\n",
      "Leacock-Chodorow Similarity: 2.9444389791664407\n",
      "Wu-Palmer Similarity: 0.631578947368421\n",
      "Lin Similarity: 0.9067798595489287\n",
      "\n",
      "** male_child and woman **\n",
      "Least Common Subsumers: ['person']\n",
      "Path Similarity: 0.2\n",
      "Leacock-Chodorow Similarity: 2.0281482472922856\n",
      "Wu-Palmer Similarity: 0.6666666666666666\n",
      "Lin Similarity: 0.31842335630818425\n",
      "\n",
      "All the other combinations have no relation whatsoever\n"
     ]
    }
   ],
   "source": [
    "# Mandatory exercise\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.corpus import wordnet_ic\n",
    "\n",
    "brown_ic = wordnet_ic.ic('ic-brown.dat')\n",
    "\n",
    "pairs = [('the','DT'), ('man','NN'), ('swim','VB'), ('with', 'PR'), ('a', 'DT'), ('girl','NN'), ('and', 'CC'), ('a', 'DT'), ('boy', 'NN'), ('whilst', 'PR'), ('the','DT'), ('woman', 'NN'), ('walk', 'VB')]\n",
    "synsets = [wn.synset(p[0] + '.' + p[1][0].lower() + '.01') for p in pairs if p[1][0] in ['N', 'V']]\n",
    "\n",
    "freqs = nltk.FreqDist(w.lower() for w in brown.words())\n",
    "for i in range(len(synsets)):\n",
    "    for j in range(i+1,len(synsets)):\n",
    "        s1, s2 = synsets[i], synsets[j]\n",
    "        \n",
    "        if s1.name().split('.')[1] == s2.name().split('.')[1]:\n",
    "            lch = [x.name().split('.')[0] for x in s1.lowest_common_hypernyms(s2)]\n",
    "            ps = s1.path_similarity(s2) if s1.path_similarity(s2) is not None else 0\n",
    "            wups = s1.wup_similarity(s2) if s1.wup_similarity(s2) is not None else 0\n",
    "\n",
    "            print('** ' + str(s1.name().split('.')[0]) + ' and ' + str(s2.name().split('.')[0]) + ' **')\n",
    "            print('Least Common Subsumers: ' + str(lch))\n",
    "            print('Path Similarity: ' + str(ps))\n",
    "            print('Leacock-Chodorow Similarity: ' + str(s1.lch_similarity(s2)))\n",
    "            print('Wu-Palmer Similarity: ' + str(wups))\n",
    "            print('Lin Similarity: ' + str(s1.lin_similarity(s2, brown_ic)))\n",
    "            print()\n",
    "\n",
    "print(\"All the other combinations have no relation whatsoever\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In our opinion, the best similarity would be Lin Similarity.\n",
    "# It uses the Information Content (IC) of the Least Common Subsumer\n",
    "# to get its result and it seems to return the most accurate similarities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional Exercises\n",
    "# Develop a function to search and show the shortest path\n",
    "# between two noun synset.\n",
    "# Apply it to show the shortest path between dog.n.01 and\n",
    "# cat.n.01.\n",
    "\n",
    "import math\n",
    "from six import iteritems\n",
    "\n",
    "# Based on nltk shortest_path_distance implementation\n",
    "# Searches first for the shortest path Synset and \n",
    "# then prints the path from each synset\n",
    "def searchAndShowPath(s1, s2):\n",
    "    shp1 = s1._shortest_hypernym_paths(False)\n",
    "    shp2 = s2._shortest_hypernym_paths(False)\n",
    "    \n",
    "    indexsyn = None\n",
    "    inf = float('inf')\n",
    "    path_distance = inf\n",
    "    for synset, d1 in iteritems(shp1):\n",
    "        d2 = shp2.get(synset, inf)\n",
    "        dsum = d1 + d2\n",
    "        \n",
    "        if dsum < path_distance:\n",
    "            indexsyn = synset\n",
    "            path_distance = dsum\n",
    "    \n",
    "    if math.isinf(path_distance):\n",
    "        print('No path distance')\n",
    "        return None\n",
    "    \n",
    "    printPath(s1, shp1, indexsyn)\n",
    "    printPath(s2, shp2, indexsyn)\n",
    "\n",
    "def printPath(s, shp, insyn):\n",
    "    count = 0\n",
    "    space = ' '\n",
    "    for synset, d in iteritems(shp):\n",
    "        print(str(count*space) + str(d) + ' ' + str(synset))\n",
    "        count +=1\n",
    "        if(synset == insyn):\n",
    "            break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Synset('dog.n.01')\n",
      " 1 Synset('canine.n.02')\n",
      "  1 Synset('domestic_animal.n.01')\n",
      "   2 Synset('carnivore.n.01')\n",
      "0 Synset('cat.n.01')\n",
      " 1 Synset('feline.n.01')\n",
      "  2 Synset('carnivore.n.01')\n"
     ]
    }
   ],
   "source": [
    "dog = wn.synset('dog.n.01')\n",
    "cat = wn.synset('cat.n.01')\n",
    "\n",
    "# prints distance and synset\n",
    "searchAndShowPath(dog, cat)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
