{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package treebank to\n",
      "[nltk_data]     /home/santiago/nltk_data...\n",
      "[nltk_data]   Package treebank is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download(\"treebank\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'HMM': [0.173, 0.221, 0.262, 0.304, 0.335, 0.369], 'TnT': [0.747, 0.796, 0.827, 0.848, 0.862, 0.875], 'PER': [0.911, 0.933, 0.942, 0.947, 0.951, 0.955], 'CRF': [0.91, 0.925, 0.933, 0.939, 0.943, 0.948]}\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import treebank\n",
    "from nltk.tag.hmm import HiddenMarkovModelTrainer\n",
    "from nltk.tag import tnt, CRFTagger\n",
    "from nltk.tag.perceptron import PerceptronTagger\n",
    "\n",
    "data = treebank.tagged_sents()\n",
    "HMMtrainer = HiddenMarkovModelTrainer()\n",
    "TnT = tnt.TnT()\n",
    "PER = PerceptronTagger(load=False)\n",
    "CRF = CRFTagger()\n",
    "sizes = [500, 1000, 1500, 2000, 2500, 3000]\n",
    "accuracies = {'HMM': [], 'TnT': [], 'PER': [], 'CRF': []}\n",
    "\n",
    "for s in sizes:\n",
    "    HMM = HMMtrainer.train_supervised(data[:s])\n",
    "    accuracies['HMM'].append(round(HMM.evaluate(data[3001:]), 3))\n",
    "    \n",
    "    TnT.train(data[:s])\n",
    "    accuracies['TnT'].append(round(TnT.evaluate(data[3001:]), 3))\n",
    "    \n",
    "    PER.train(data[:s])\n",
    "    accuracies['PER'].append(round(PER.evaluate(data[3001:]), 3))\n",
    "    \n",
    "    CRF.train(data[:s], 'crf_tagger_model')\n",
    "    accuracies['CRF'].append(round(CRF.evaluate(data[3001:]), 3))\n",
    "\n",
    "print(accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "for a in accuracies:\n",
    "    plt.plot(sizes, accuracies[a])\n",
    "plt.xlabel('Training data size')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(accuracies.keys())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We would choose the perceptron since it is the one\n",
    "# that performs better regardless of the training data size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SMS Spam filter from lab3:\n",
    "\n",
    "import numpy as np\n",
    "import string\n",
    "\n",
    "# load data\n",
    "data = np.loadtxt('smsspamcollection/SMSSpamCollection', dtype='str',delimiter='\\t')\n",
    "\n",
    "# pre process\n",
    "#remove punctuation and lower chars\n",
    "translator = str.maketrans('', '', string.punctuation)\n",
    "for i in range(data.shape[0]):\n",
    "    data[i,1] = data[i,1].translate(translator).lower()\n",
    "    \n",
    "#Single validation 50/50\n",
    "train = data[:2787]\n",
    "test = data[2787:]\n",
    "\n",
    "#random shuffle\n",
    "np.random.shuffle(train)\n",
    "np.random.shuffle(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for classifier:  knn  with vectorizer:  CountVectorizer\n",
      "Accuracy score:  0.94\n",
      "     |         s |\n",
      "     |    h    p |\n",
      "     |    a    a |\n",
      "     |    m    m |\n",
      "-----+-----------+\n",
      " ham |<2420>   1 |\n",
      "spam |  165 <201>|\n",
      "-----+-----------+\n",
      "(row = reference; col = test)\n",
      "\n",
      "Results for classifier:  svc  with vectorizer:  CountVectorizer\n",
      "Accuracy score:  0.978\n",
      "     |         s |\n",
      "     |    h    p |\n",
      "     |    a    a |\n",
      "     |    m    m |\n",
      "-----+-----------+\n",
      " ham |<2413>   8 |\n",
      "spam |   53 <313>|\n",
      "-----+-----------+\n",
      "(row = reference; col = test)\n",
      "\n",
      "Results for classifier:  knn  with vectorizer:  TfidfVectorizer\n",
      "Accuracy score:  0.975\n",
      "     |         s |\n",
      "     |    h    p |\n",
      "     |    a    a |\n",
      "     |    m    m |\n",
      "-----+-----------+\n",
      " ham |<2412>   9 |\n",
      "spam |   61 <305>|\n",
      "-----+-----------+\n",
      "(row = reference; col = test)\n",
      "\n",
      "Results for classifier:  svc  with vectorizer:  TfidfVectorizer\n",
      "Accuracy score:  0.981\n",
      "     |         s |\n",
      "     |    h    p |\n",
      "     |    a    a |\n",
      "     |    m    m |\n",
      "-----+-----------+\n",
      " ham |<2416>   5 |\n",
      "spam |   48 <318>|\n",
      "-----+-----------+\n",
      "(row = reference; col = test)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.neighbors import KNeighborsClassifier, DistanceMetric, NearestNeighbors\n",
    "from sklearn.svm import SVC\n",
    "from nltk.metrics import ConfusionMatrix\n",
    "from nltk.metrics.scores import accuracy\n",
    "\n",
    "cv = CountVectorizer()\n",
    "tfcv = TfidfVectorizer()\n",
    "knn = KNeighborsClassifier(1)\n",
    "svc = SVC(kernel='linear')\n",
    "\n",
    "vectorizers = [[cv, 'CountVectorizer'],[tfcv,'TfidfVectorizer']]\n",
    "classifiers = [[knn,'knn'], [svc,'svc']]\n",
    "\n",
    "#Classifiers with KNN and SVM with linear kernel\n",
    "#Also using two vectorizers Count and Tfid\n",
    "#The best combination seems to be the SVM with Tfid vectorizer, but \n",
    "#they all obtain a high accuracy\n",
    "for v in vectorizers:\n",
    "    vectorizer = v[0]\n",
    "    Xtrn = vectorizer.fit_transform([''.join(ex[1]) for ex in train])\n",
    "    Xtst = vectorizer.transform([''.join(ex[1]) for ex in test])\n",
    "    Ytrn = [ex[0] for ex in train]\n",
    "    Ytst = [ex[0] for ex in test]\n",
    "    for classifier in classifiers:\n",
    "        clf = classifier[0]\n",
    "        clf.fit(Xtrn, Ytrn)\n",
    "        preds = clf.predict(Xtst).tolist()\n",
    "        print('Results for classifier: ',classifier[1], ' with vectorizer: ', v[1])\n",
    "        print('Accuracy score: ', round(accuracy(test[:,0], preds), 3))\n",
    "        print(ConfusionMatrix(test[:,0].tolist(), preds).pretty_format())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.metrics.distance import jaccard_distance\n",
    "\n",
    "def kNN(ex, d):\n",
    "    return min(trnlist, key=lambda x: d(ex[1], x[1]))[0]\n",
    "\n",
    "\n",
    "def jaccard_d(a,b):                                       \n",
    "    return jaccard_distance(set(a), set(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:  0.761\n",
      "     |         s |\n",
      "     |    h    p |\n",
      "     |    a    a |\n",
      "     |    m    m |\n",
      "-----+-----------+\n",
      " ham |<2081> 340 |\n",
      "spam |  325  <41>|\n",
      "-----+-----------+\n",
      "(row = reference; col = test)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# KNN with jaccard distance\n",
    "\n",
    "import nltk\n",
    "\n",
    "trnlist = train.tolist()\n",
    "tstlist = test.tolist()\n",
    "\n",
    "for i in range(len(train)):\n",
    "    sentences = nltk.sent_tokenize(train[i][1])\n",
    "    words = [nltk.word_tokenize(sent) for sent in sentences]\n",
    "    trnlist[i][1] = words[0]\n",
    "    \n",
    "for i in range(len(test)):\n",
    "    sentences = nltk.sent_tokenize(train[i][1])\n",
    "    words = [nltk.word_tokenize(sent) for sent in sentences]\n",
    "    tstlist[i][1] = words[0]\n",
    "\n",
    "preds = []\n",
    "refs = []\n",
    "for tst in tstlist:\n",
    "    preds.append(kNN(tst, jaccard_d))\n",
    "    refs.append(tst[0])\n",
    "    \n",
    "print('Accuracy score: ', round(accuracy(refs, preds), 3))\n",
    "print(ConfusionMatrix(refs, preds).pretty_format())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(p):\n",
    "    if p[1][0] in {'N', 'V'}:\n",
    "        return wnl.lemmatize(p[0].lower(), pos=p[1][0].lower())\n",
    "    return p[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:  0.761\n",
      "     |         s |\n",
      "     |    h    p |\n",
      "     |    a    a |\n",
      "     |    m    m |\n",
      "-----+-----------+\n",
      " ham |<2081> 340 |\n",
      "spam |  325  <41>|\n",
      "-----+-----------+\n",
      "(row = reference; col = test)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# KNN with lemmas\n",
    "\n",
    "from nltk import pos_tag\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "wnl = WordNetLemmatizer()\n",
    "\n",
    "trnlist = train.tolist()\n",
    "tstlist = test.tolist()\n",
    "\n",
    "for i in range(len(train)):\n",
    "    sentences = nltk.sent_tokenize(train[i][1])\n",
    "    words = [nltk.word_tokenize(sent) for sent in sentences]\n",
    "    pairs = [pos_tag(w) for w in words]\n",
    "    l_words = [[lemmatize(p) for p in pair] for pair in pairs]\n",
    "    trnlist[i][1] = l_words[0]\n",
    "    \n",
    "for i in range(len(test)):\n",
    "    sentences = nltk.sent_tokenize(train[i][1])\n",
    "    words = [nltk.word_tokenize(sent) for sent in sentences]\n",
    "    pairs = [pos_tag(w) for w in words]\n",
    "    l_words = [[lemmatize(p) for p in pair] for pair in pairs]\n",
    "    tstlist[i][1] = l_words[0]\n",
    "    \n",
    "preds = []\n",
    "refs = []\n",
    "for tst in tstlist:\n",
    "    preds.append(kNN(tst, jaccard_d))\n",
    "    refs.append(tst[0])\n",
    "    \n",
    "print('Accuracy score: ', round(accuracy(refs, preds), 3))\n",
    "print(ConfusionMatrix(refs, preds).pretty_format())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
