{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import stuff\n",
    "import spacy\n",
    "import wmd\n",
    "import nltk\n",
    "from nltk import pos_tag\n",
    "from nltk.wsd import lesk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.metrics import jaccard_distance\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize \n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "#download other stuff\n",
    "\n",
    "#nltk.download('stopwords')\n",
    "#python3 -m spacy download en_core_web_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#init stuff\n",
    "wnl = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english')) \n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "nlp.add_pipe(wmd.WMD.SpacySimilarityHook(nlp), last=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#general methods\n",
    "def lemmatize(p):\n",
    "    if p[1][0] in {'N', 'V'}:\n",
    "        return wnl.lemmatize(p[0].lower(), pos=p[1][0].lower())\n",
    "    return p[0]\n",
    "\n",
    "def penn2morphy(penntag, returnNone=False):\n",
    "    morphy_tag = {'NN':wn.NOUN, 'JJ':wn.ADJ,\n",
    "                  'VB':wn.VERB, 'RB':wn.ADV}\n",
    "    try:\n",
    "        return morphy_tag[penntag[:2]]\n",
    "    except:\n",
    "        return None if returnNone else ''\n",
    "    \n",
    "def get_cosine_sim(*strs): \n",
    "    vectors = [t for t in get_vectors(*strs)]\n",
    "    return cosine_similarity(vectors)\n",
    "    \n",
    "def get_vectors(*strs):\n",
    "    text = [t for t in strs]\n",
    "    vectorizer = CountVectorizer(text)\n",
    "    vectorizer.fit(text)\n",
    "    return vectorizer.transform(text).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distances(input_file):  \n",
    "    with open(input_file) as f:\n",
    "        input_data = f.readlines()\n",
    "    \n",
    "    lesks_distances = []\n",
    "    morphology_distances = []\n",
    "    cosine_distances = []\n",
    "    wmd_distances = []\n",
    "    for i in input_data:\n",
    "        #sentences = nltk.sent_tokenize(i)\n",
    "        #gets sentences\n",
    "        sentences = i.replace('\\n','').split('\\t')\n",
    "        \n",
    "        #tokenize\n",
    "        words = [word_tokenize(sent) for sent in sentences]\n",
    "        \n",
    "        #filtering stop words\n",
    "        filtered = [[w for w in s if not w in stop_words ]for s in words]\n",
    "        \n",
    "        #pos tag\n",
    "        pairs = [pos_tag(w) for w in filtered]\n",
    "        \n",
    "        #lemma words\n",
    "        l_words = [[lemmatize(p) for p in pair] for pair in pairs]\n",
    "        \n",
    "        #synsets of the tokenized\n",
    "        synsets = [[[lesk(w, p[0], pos=penn2morphy(p[1][0])) for p in pair] for pair in pairs] for w in filtered]\n",
    "\n",
    "        #lemmatized sentences\n",
    "        lemmasent = [' '.join(l) for l in l_words]\n",
    "        \n",
    "        morphology_distances.append(jaccard_distance(set(l_words[0]),set(l_words[1])))\n",
    "        lesks_distances.append(jaccard_distance(set(synsets[0][0]), set(synsets[1][1])))\n",
    "        cosine_distances.append(get_cosine_sim(lemmasent[0],lemmasent[1])[0][1])\n",
    "        wmd_distances.append(nlp(sentences[0]).similarity(nlp(sentences[1])))\n",
    "    \n",
    "    #normalizing\n",
    "    norm_wmd_distance = [float(i)/max(wmd_distances) for i in wmd_distances]\n",
    "                             \n",
    "    #print(\"Cosine distances: \" + str(cosine_distances))\n",
    "    #print(\"Lesk distance: \" + str(lesks_distances))\n",
    "    #print(\"Lemma distances: \" + str(morphology_distances))\n",
    "    #print(\"WMD distances: \" + str(norm_wmd_distance))\n",
    "    \n",
    "    gold_file = 'data/train/STS.gs.MSRpar.txt'\n",
    "    with open(gold_file) as f:\n",
    "        gold_data = f.readlines()\n",
    "    gold = [float(g.replace('\\n', '')) for g in gold_data]\n",
    "        \n",
    "    cos_pearson = pearsonr(cosine_distances, gold)[0]\n",
    "    mor_pearson = pearsonr(morphology_distances, gold)[0]\n",
    "    lesk_pearson = pearsonr(lesks_distances, gold)[0]\n",
    "    wmd_pearson = pearsonr(norm_wmd_distance, gold)[0]\n",
    "\n",
    "    print('Cosine correlation: ' + str(cos_pearson))\n",
    "    print('Lemmatized words correlation: ' + str(mor_pearson))\n",
    "    print('Lesk correlation: ' + str(lesk_pearson))\n",
    "    print(\"WMD correlation: \" + str(wmd_pearson))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine correlation: 0.5624454928407743\n",
      "Lemmatized words correlation: -0.5374512978162805\n",
      "Lesk correlation: -0.43219148526405204\n",
      "WMD correlation: -0.5061061956812528\n"
     ]
    }
   ],
   "source": [
    "train_1 = 'data/train/STS.input.MSRpar.txt'\n",
    "distances(train_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4.0,\n",
       " 3.75,\n",
       " 2.8,\n",
       " 3.4,\n",
       " 2.4,\n",
       " 1.333,\n",
       " 4.6,\n",
       " 3.8,\n",
       " 4.2,\n",
       " 2.6,\n",
       " 4.4,\n",
       " 4.2,\n",
       " 5.0,\n",
       " 5.0,\n",
       " 5.0,\n",
       " 3.4,\n",
       " 5.0,\n",
       " 4.0,\n",
       " 3.2,\n",
       " 5.0,\n",
       " 4.4,\n",
       " 3.6,\n",
       " 3.6,\n",
       " 0.8,\n",
       " 1.4,\n",
       " 3.2,\n",
       " 3.8,\n",
       " 4.2,\n",
       " 3.0,\n",
       " 3.6,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 4.8,\n",
       " 2.5,\n",
       " 2.25,\n",
       " 3.5,\n",
       " 3.5,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.667,\n",
       " 1.667,\n",
       " 3.6,\n",
       " 3.8,\n",
       " 3.4,\n",
       " 3.4,\n",
       " 3.8,\n",
       " 2.8,\n",
       " 3.75,\n",
       " 4.4,\n",
       " 3.75,\n",
       " 2.75,\n",
       " 3.75,\n",
       " 2.25,\n",
       " 3.8,\n",
       " 3.2,\n",
       " 3.8,\n",
       " 4.8,\n",
       " 4.0,\n",
       " 1.4,\n",
       " 4.2,\n",
       " 1.8,\n",
       " 4.2,\n",
       " 2.0,\n",
       " 2.6,\n",
       " 3.25,\n",
       " 5.0,\n",
       " 3.0,\n",
       " 3.75,\n",
       " 4.25,\n",
       " 4.75,\n",
       " 3.25,\n",
       " 3.75,\n",
       " 3.25,\n",
       " 3.8,\n",
       " 5.0,\n",
       " 3.6,\n",
       " 3.8,\n",
       " 2.0,\n",
       " 3.4,\n",
       " 4.2,\n",
       " 3.4,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.25,\n",
       " 2.75,\n",
       " 2.6,\n",
       " 3.4,\n",
       " 3.6,\n",
       " 3.6,\n",
       " 4.8,\n",
       " 4.0,\n",
       " 3.6,\n",
       " 3.4,\n",
       " 2.4,\n",
       " 4.222,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 2.75,\n",
       " 4.0,\n",
       " 1.75,\n",
       " 1.75,\n",
       " 4.5,\n",
       " 3.25,\n",
       " 5.0,\n",
       " 3.0,\n",
       " 2.8,\n",
       " 2.667,\n",
       " 4.0,\n",
       " 4.4,\n",
       " 4.25,\n",
       " 4.176,\n",
       " 3.0,\n",
       " 2.5,\n",
       " 3.8,\n",
       " 4.6,\n",
       " 1.4,\n",
       " 2.8,\n",
       " 2.8,\n",
       " 4.2,\n",
       " 1.0,\n",
       " 4.2,\n",
       " 2.75,\n",
       " 2.5,\n",
       " 3.5,\n",
       " 4.75,\n",
       " 3.0,\n",
       " 3.5,\n",
       " 4.0,\n",
       " 2.0,\n",
       " 3.2,\n",
       " 3.6,\n",
       " 3.8,\n",
       " 5.0,\n",
       " 4.0,\n",
       " 3.0,\n",
       " 2.5,\n",
       " 3.0,\n",
       " 4.0,\n",
       " 2.0,\n",
       " 3.0,\n",
       " 2.625,\n",
       " 3.2,\n",
       " 4.0,\n",
       " 3.2,\n",
       " 2.4,\n",
       " 4.4,\n",
       " 3.6,\n",
       " 2.4,\n",
       " 3.6,\n",
       " 4.6,\n",
       " 4.4,\n",
       " 4.4,\n",
       " 4.6,\n",
       " 4.4,\n",
       " 2.6,\n",
       " 3.6,\n",
       " 4.2,\n",
       " 3.2,\n",
       " 2.0,\n",
       " 2.8,\n",
       " 1.6,\n",
       " 3.4,\n",
       " 4.0,\n",
       " 2.6,\n",
       " 2.8,\n",
       " 3.0,\n",
       " 3.6,\n",
       " 5.0,\n",
       " 3.4,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 3.5,\n",
       " 4.5,\n",
       " 3.2,\n",
       " 3.8,\n",
       " 3.2,\n",
       " 4.0,\n",
       " 3.25,\n",
       " 3.0,\n",
       " 4.25,\n",
       " 1.5,\n",
       " 4.25,\n",
       " 4.25,\n",
       " 0.75,\n",
       " 3.0,\n",
       " 3.5,\n",
       " 3.75,\n",
       " 4.0,\n",
       " 1.75,\n",
       " 1.75,\n",
       " 3.75,\n",
       " 4.0,\n",
       " 2.0,\n",
       " 3.4,\n",
       " 1.4,\n",
       " 4.8,\n",
       " 2.0,\n",
       " 3.4,\n",
       " 2.4,\n",
       " 3.4,\n",
       " 4.8,\n",
       " 2.6,\n",
       " 2.4,\n",
       " 2.6,\n",
       " 2.8,\n",
       " 4.4,\n",
       " 3.2,\n",
       " 2.4,\n",
       " 4.0,\n",
       " 3.25,\n",
       " 4.0,\n",
       " 2.75,\n",
       " 4.0,\n",
       " 3.6,\n",
       " 3.6,\n",
       " 4.4,\n",
       " 3.8,\n",
       " 4.2,\n",
       " 3.6,\n",
       " 4.6,\n",
       " 3.6,\n",
       " 3.25,\n",
       " 4.0,\n",
       " 4.5,\n",
       " 2.5,\n",
       " 3.75,\n",
       " 4.0,\n",
       " 1.5,\n",
       " 3.75,\n",
       " 3.455,\n",
       " 5.0,\n",
       " 3.75,\n",
       " 4.0,\n",
       " 2.5,\n",
       " 0.25,\n",
       " 1.75,\n",
       " 5.0,\n",
       " 3.833,\n",
       " 3.75,\n",
       " 3.25,\n",
       " 2.75,\n",
       " 3.0,\n",
       " 4.4,\n",
       " 3.2,\n",
       " 4.6,\n",
       " 3.6,\n",
       " 4.4,\n",
       " 3.4,\n",
       " 4.056,\n",
       " 3.5,\n",
       " 5.0,\n",
       " 3.0,\n",
       " 3.75,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.75,\n",
       " 3.75,\n",
       " 3.8,\n",
       " 4.0,\n",
       " 3.5,\n",
       " 3.0,\n",
       " 3.176,\n",
       " 4.2,\n",
       " 3.4,\n",
       " 4.6,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 3.25,\n",
       " 3.643,\n",
       " 3.6,\n",
       " 4.0,\n",
       " 1.0,\n",
       " 3.4,\n",
       " 1.75,\n",
       " 3.0,\n",
       " 3.25,\n",
       " 2.75,\n",
       " 3.4,\n",
       " 3.6,\n",
       " 3.2,\n",
       " 3.2,\n",
       " 2.8,\n",
       " 2.4,\n",
       " 3.4,\n",
       " 3.6,\n",
       " 3.8,\n",
       " 3.4,\n",
       " 4.8,\n",
       " 3.8,\n",
       " 3.333,\n",
       " 2.5,\n",
       " 3.5,\n",
       " 1.9,\n",
       " 3.0,\n",
       " 3.6,\n",
       " 2.4,\n",
       " 3.2,\n",
       " 2.0,\n",
       " 3.8,\n",
       " 3.0,\n",
       " 3.692,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 2.75,\n",
       " 3.25,\n",
       " 3.25,\n",
       " 3.75,\n",
       " 3.6,\n",
       " 3.5,\n",
       " 5.0,\n",
       " 3.75,\n",
       " 3.0,\n",
       " 4.0,\n",
       " 3.333,\n",
       " 3.333,\n",
       " 4.667,\n",
       " 3.333,\n",
       " 2.6,\n",
       " 2.4,\n",
       " 3.857,\n",
       " 1.8,\n",
       " 3.6,\n",
       " 2.4,\n",
       " 3.0,\n",
       " 2.0,\n",
       " 1.6,\n",
       " 4.0,\n",
       " 3.6,\n",
       " 3.8,\n",
       " 4.4,\n",
       " 3.0,\n",
       " 3.8,\n",
       " 3.0,\n",
       " 4.25,\n",
       " 1.273,\n",
       " 1.0,\n",
       " 3.0,\n",
       " 4.0,\n",
       " 3.5,\n",
       " 4.0,\n",
       " 3.25,\n",
       " 2.0,\n",
       " 1.0,\n",
       " 3.0,\n",
       " 2.6,\n",
       " 2.6,\n",
       " 4.6,\n",
       " 3.2,\n",
       " 3.0,\n",
       " 4.75,\n",
       " 2.75,\n",
       " 4.5,\n",
       " 2.75,\n",
       " 2.2,\n",
       " 3.0,\n",
       " 2.4,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 4.0,\n",
       " 2.588,\n",
       " 3.6,\n",
       " 4.667,\n",
       " 3.333,\n",
       " 2.333,\n",
       " 3.333,\n",
       " 3.0,\n",
       " 2.25,\n",
       " 2.5,\n",
       " 3.25,\n",
       " 4.0,\n",
       " 4.5,\n",
       " 3.5,\n",
       " 4.75,\n",
       " 2.0,\n",
       " 3.6,\n",
       " 2.769,\n",
       " 3.4,\n",
       " 4.0,\n",
       " 3.5,\n",
       " 2.0,\n",
       " 4.0,\n",
       " 2.8,\n",
       " 1.4,\n",
       " 4.0,\n",
       " 3.2,\n",
       " 1.8,\n",
       " 3.4,\n",
       " 4.733,\n",
       " 1.6,\n",
       " 3.2,\n",
       " 4.8,\n",
       " 1.4,\n",
       " 2.6,\n",
       " 3.5,\n",
       " 3.75,\n",
       " 3.25,\n",
       " 1.75,\n",
       " 3.0,\n",
       " 3.5,\n",
       " 3.25,\n",
       " 0.5,\n",
       " 2.25,\n",
       " 4.0,\n",
       " 3.25,\n",
       " 4.25,\n",
       " 2.4,\n",
       " 2.4,\n",
       " 4.0,\n",
       " 3.0,\n",
       " 3.4,\n",
       " 3.8,\n",
       " 4.0,\n",
       " 3.2,\n",
       " 3.5,\n",
       " 2.5,\n",
       " 4.5,\n",
       " 4.5,\n",
       " 3.6,\n",
       " 2.8,\n",
       " 4.8,\n",
       " 0.8,\n",
       " 4.091,\n",
       " 2.25,\n",
       " 5.0,\n",
       " 3.75,\n",
       " 3.667,\n",
       " 2.667,\n",
       " 3.333,\n",
       " 3.0,\n",
       " 3.444,\n",
       " 3.8,\n",
       " 3.0,\n",
       " 3.6,\n",
       " 3.75,\n",
       " 5.0,\n",
       " 3.0,\n",
       " 3.25,\n",
       " 3.4,\n",
       " 3.8,\n",
       " 3.6,\n",
       " 3.4,\n",
       " 3.6,\n",
       " 2.4,\n",
       " 2.4,\n",
       " 2.4,\n",
       " 4.5,\n",
       " 0.889,\n",
       " 3.25,\n",
       " 4.75,\n",
       " 4.75,\n",
       " 4.0,\n",
       " 3.5,\n",
       " 5.0,\n",
       " 3.6,\n",
       " 3.0,\n",
       " 3.8,\n",
       " 3.0,\n",
       " 1.8,\n",
       " 4.8,\n",
       " 3.8,\n",
       " 3.6,\n",
       " 4.0,\n",
       " 4.6,\n",
       " 3.8,\n",
       " 4.8,\n",
       " 2.0,\n",
       " 3.2,\n",
       " 2.2,\n",
       " 4.0,\n",
       " 4.2,\n",
       " 2.0,\n",
       " 1.2,\n",
       " 4.0,\n",
       " 3.0,\n",
       " 0.8,\n",
       " 2.8,\n",
       " 3.0,\n",
       " 3.8,\n",
       " 4.4,\n",
       " 2.6,\n",
       " 1.4,\n",
       " 3.2,\n",
       " 1.6,\n",
       " 3.0,\n",
       " 3.273,\n",
       " 4.0,\n",
       " 3.25,\n",
       " 3.25,\n",
       " 5.0,\n",
       " 3.5,\n",
       " 3.417,\n",
       " 1.75,\n",
       " 2.7,\n",
       " 2.75,\n",
       " 3.75,\n",
       " 3.75,\n",
       " 4.111,\n",
       " 3.6,\n",
       " 4.0,\n",
       " 4.2,\n",
       " 3.75,\n",
       " 3.8,\n",
       " 4.4,\n",
       " 3.6,\n",
       " 4.6,\n",
       " 1.667,\n",
       " 4.0,\n",
       " 4.333,\n",
       " 3.0,\n",
       " 3.5,\n",
       " 3.5,\n",
       " 2.0,\n",
       " 3.75,\n",
       " 2.0,\n",
       " 4.333,\n",
       " 1.8,\n",
       " 2.667,\n",
       " 3.8,\n",
       " 3.2,\n",
       " 2.8,\n",
       " 2.2,\n",
       " 4.333,\n",
       " 2.0,\n",
       " 3.0,\n",
       " 2.333,\n",
       " 3.25,\n",
       " 2.25,\n",
       " 3.5,\n",
       " 2.25,\n",
       " 0.75,\n",
       " 4.0,\n",
       " 3.5,\n",
       " 5.0,\n",
       " 3.75,\n",
       " 3.75,\n",
       " 4.25,\n",
       " 4.5,\n",
       " 4.0,\n",
       " 3.25,\n",
       " 0.75,\n",
       " 2.75,\n",
       " 4.0,\n",
       " 3.4,\n",
       " 2.2,\n",
       " 3.4,\n",
       " 3.4,\n",
       " 2.6,\n",
       " 3.4,\n",
       " 3.6,\n",
       " 3.25,\n",
       " 5.0,\n",
       " 4.25,\n",
       " 3.4,\n",
       " 4.25,\n",
       " 3.25,\n",
       " 4.25,\n",
       " 3.75,\n",
       " 3.667,\n",
       " 4.333,\n",
       " 3.909,\n",
       " 3.933,\n",
       " 3.75,\n",
       " 3.75,\n",
       " 4.25,\n",
       " 4.25,\n",
       " 3.5,\n",
       " 4.75,\n",
       " 3.25,\n",
       " 2.75,\n",
       " 3.0,\n",
       " 3.8,\n",
       " 3.4,\n",
       " 3.857,\n",
       " 4.0,\n",
       " 3.4,\n",
       " 3.2,\n",
       " 3.0,\n",
       " 3.2,\n",
       " 3.6,\n",
       " 1.6,\n",
       " 3.8,\n",
       " 2.6,\n",
       " 1.6,\n",
       " 2.0,\n",
       " 3.6,\n",
       " 4.5,\n",
       " 4.0,\n",
       " 3.0,\n",
       " 2.5,\n",
       " 3.5,\n",
       " 3.0,\n",
       " 3.769,\n",
       " 3.4,\n",
       " 1.8,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.4,\n",
       " 4.25,\n",
       " 3.25,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 3.625,\n",
       " 4.25,\n",
       " 3.5,\n",
       " 4.0,\n",
       " 3.2,\n",
       " 3.4,\n",
       " 4.0,\n",
       " 3.4,\n",
       " 2.8,\n",
       " 3.6,\n",
       " 4.8,\n",
       " 3.8,\n",
       " 2.4,\n",
       " 1.6,\n",
       " 3.2,\n",
       " 3.8,\n",
       " 4.2,\n",
       " 5.0,\n",
       " 3.4,\n",
       " 1.0,\n",
       " 3.333,\n",
       " 4.0,\n",
       " 3.333,\n",
       " 3.2,\n",
       " 4.0,\n",
       " 3.8,\n",
       " 2.2,\n",
       " 3.75,\n",
       " 3.0,\n",
       " 1.25,\n",
       " 3.25,\n",
       " 3.333,\n",
       " 2.0,\n",
       " 3.0,\n",
       " 2.667,\n",
       " 3.667,\n",
       " 3.667,\n",
       " 4.333,\n",
       " 1.333,\n",
       " 2.2,\n",
       " 1.2,\n",
       " 4.4,\n",
       " 3.4,\n",
       " 4.2,\n",
       " 3.0,\n",
       " 3.4,\n",
       " 4.8,\n",
       " 2.75,\n",
       " 4.0,\n",
       " 1.0,\n",
       " 4.25,\n",
       " 3.0,\n",
       " 3.5,\n",
       " 4.25,\n",
       " 4.0,\n",
       " 1.75,\n",
       " 3.067,\n",
       " 3.25,\n",
       " 3.75,\n",
       " 2.25,\n",
       " 2.5,\n",
       " 3.75,\n",
       " 3.25,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 3.444,\n",
       " 2.75,\n",
       " 4.6,\n",
       " 2.8,\n",
       " 4.8,\n",
       " 0.6,\n",
       " 2.75,\n",
       " 2.75,\n",
       " 3.25,\n",
       " 3.25,\n",
       " 2.5,\n",
       " 2.25,\n",
       " 1.5,\n",
       " 3.0,\n",
       " 3.8,\n",
       " 4.308,\n",
       " 3.4,\n",
       " 3.2,\n",
       " 3.5,\n",
       " 3.75,\n",
       " 1.75,\n",
       " 1.25,\n",
       " 3.4,\n",
       " 1.2,\n",
       " 3.8,\n",
       " 3.2,\n",
       " 3.5,\n",
       " 4.75,\n",
       " 3.5,\n",
       " 2.0,\n",
       " 2.8,\n",
       " 1.4,\n",
       " 2.0,\n",
       " 4.8,\n",
       " 3.8,\n",
       " 4.6,\n",
       " 1.4,\n",
       " 3.6,\n",
       " 3.0,\n",
       " 1.6,\n",
       " 4.0,\n",
       " 2.4,\n",
       " 3.5,\n",
       " 0.75,\n",
       " 5.0,\n",
       " 5.0,\n",
       " 4.0,\n",
       " 3.0,\n",
       " 1.333,\n",
       " 3.667,\n",
       " 3.091,\n",
       " 3.8,\n",
       " 4.4,\n",
       " 4.8,\n",
       " 3.0,\n",
       " 2.667,\n",
       " 4.0,\n",
       " 3.0,\n",
       " 4.0,\n",
       " 5.0,\n",
       " 3.4,\n",
       " 3.4,\n",
       " 3.857,\n",
       " 2.75,\n",
       " 4.0,\n",
       " 1.5,\n",
       " 3.75,\n",
       " 2.75,\n",
       " 4.0,\n",
       " 1.5,\n",
       " 1.8,\n",
       " 4.0,\n",
       " 3.0,\n",
       " 3.6,\n",
       " 3.4,\n",
       " 3.0,\n",
       " 2.6,\n",
       " 3.2,\n",
       " 3.5,\n",
       " 3.25,\n",
       " 3.75,\n",
       " 3.25]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(train_1) as f:\n",
    "    input_data = f.readlines()\n",
    "\n",
    "i = input_data[247]\n",
    "#sentences = nltk.sent_tokenize(i)\n",
    "sentences = i.replace('\\n','').split('\\t')\n",
    "words = [nltk.word_tokenize(sent) for sent in sentences]\n",
    "pairs = [pos_tag(w) for w in words]\n",
    "l_words = [[lemmatize(p) for p in pair] for pair in pairs]\n",
    "synsets = [[[lesk(w, p[0], pos=penn2morphy(p[1][0])) for p in pair] for pair in pairs] for w in words]\n",
    "lemmasent = [' '.join(l) for l in l_words]\n",
    "get_cosine_sim(sentences[0],sentences[1])[0][1]\n",
    "\n",
    "\n",
    "gold_file = 'data/train/STS.gs.MSRpar.txt'\n",
    "with open(gold_file) as f:\n",
    "    gold_data = f.readlines()\n",
    "        \n",
    "gold = [float(g.replace('\\n', '')) for g in gold_data]\n",
    "gold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4472135954999579"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_file = 'data/trial/STS.input.txt'\n",
    "with open(input_file) as f:\n",
    "    input_data = f.readlines()\n",
    "\n",
    "input_data[0]\n",
    "sentences = nltk.sent_tokenize(input_data[0])\n",
    "words = [nltk.word_tokenize(sent) for sent in sentences]\n",
    "pairs = [pos_tag(w) for w in words]\n",
    "l_words = [[lemmatize(p) for p in pair] for pair in pairs]\n",
    "synsets = [[[lesk(w, p[0], pos=penn2morphy(p[1][0])) for p in pair] for pair in pairs] for w in words]\n",
    "lemmasent = [' '.join(l) for l in l_words]\n",
    "get_cosine_sim(sentences[0],sentences[1])[0][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://medium.com/@adriensieg/text-similarities-da019229c894\n",
    "https://towardsdatascience.com/overview-of-text-similarity-metrics-3397c4601f50"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
