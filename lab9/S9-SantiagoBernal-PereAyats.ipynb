{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "\n",
    "def parse(parser, grammar, sent):\n",
    "    parser = parser(grammar)\n",
    "    parse = parser.parse(sent)\n",
    "    ts = []\n",
    "    for t in parse:\n",
    "        ts.append(t)\n",
    "        print(t)\n",
    "        t.pretty_print()\n",
    "    print('number of trees:', len(ts))\n",
    "    parse = parser.chart_parse(sent)\n",
    "    print(\"TD num edges = \", parse.num_edges())\n",
    "    pp.pprint(parse.edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parser:  <class 'nltk.parse.chart.ChartParser'>\n",
      "(S\n",
      "  (NP (JJ lazy) (NNS cats))\n",
      "  (VP (VB play) (NNS (IN with) (NNS mice))))\n",
      "               S                \n",
      "       ________|____             \n",
      "      |             VP          \n",
      "      |         ____|____        \n",
      "      NP       |        NNS     \n",
      "  ____|___     |     ____|___    \n",
      " JJ      NNS   VB   IN      NNS \n",
      " |        |    |    |        |   \n",
      "lazy     cats play with     mice\n",
      "\n",
      "number of trees: 1\n",
      "TD num edges =  32\n",
      "[   [Edge: [0:1] 'lazy'],\n",
      "    [Edge: [1:2] 'cats'],\n",
      "    [Edge: [2:3] 'play'],\n",
      "    [Edge: [3:4] 'with'],\n",
      "    [Edge: [4:5] 'mice'],\n",
      "    [Edge: [0:1] JJ -> 'lazy' *],\n",
      "    [Edge: [0:1] NP -> JJ * NNS],\n",
      "    [Edge: [1:2] NNS -> 'cats' *],\n",
      "    [Edge: [1:2] NP -> NNS *],\n",
      "    [Edge: [1:2] NNS -> NNS * CC NNS],\n",
      "    [Edge: [0:2] NP -> JJ NNS *],\n",
      "    [Edge: [0:2] S  -> NP * VP],\n",
      "    [Edge: [0:2] NP -> NP * CC NP],\n",
      "    [Edge: [1:2] S  -> NP * VP],\n",
      "    [Edge: [1:2] NP -> NP * CC NP],\n",
      "    [Edge: [2:3] VB -> 'play' *],\n",
      "    [Edge: [2:3] VP -> VB * NNS],\n",
      "    [Edge: [3:4] IN -> 'with' *],\n",
      "    [Edge: [3:4] NNS -> IN * NNS],\n",
      "    [Edge: [4:5] NNS -> 'mice' *],\n",
      "    [Edge: [4:5] NP -> NNS *],\n",
      "    [Edge: [4:5] NNS -> NNS * CC NNS],\n",
      "    [Edge: [3:5] NNS -> IN NNS *],\n",
      "    [Edge: [3:5] NP -> NNS *],\n",
      "    [Edge: [3:5] NNS -> NNS * CC NNS],\n",
      "    [Edge: [2:5] VP -> VB NNS *],\n",
      "    [Edge: [0:5] S  -> NP VP *],\n",
      "    [Edge: [1:5] S  -> NP VP *],\n",
      "    [Edge: [3:5] S  -> NP * VP],\n",
      "    [Edge: [3:5] NP -> NP * CC NP],\n",
      "    [Edge: [4:5] S  -> NP * VP],\n",
      "    [Edge: [4:5] NP -> NP * CC NP]]\n",
      "\n",
      "Parser:  <class 'nltk.parse.chart.BottomUpChartParser'>\n",
      "(S\n",
      "  (NP (JJ lazy) (NNS cats))\n",
      "  (VP (VB play) (NNS (IN with) (NNS mice))))\n",
      "               S                \n",
      "       ________|____             \n",
      "      |             VP          \n",
      "      |         ____|____        \n",
      "      NP       |        NNS     \n",
      "  ____|___     |     ____|___    \n",
      " JJ      NNS   VB   IN      NNS \n",
      " |        |    |    |        |   \n",
      "lazy     cats play with     mice\n",
      "\n",
      "number of trees: 1\n",
      "TD num edges =  54\n",
      "[   [Edge: [0:1] 'lazy'],\n",
      "    [Edge: [1:2] 'cats'],\n",
      "    [Edge: [2:3] 'play'],\n",
      "    [Edge: [3:4] 'with'],\n",
      "    [Edge: [4:5] 'mice'],\n",
      "    [Edge: [0:0] JJ -> * 'lazy'],\n",
      "    [Edge: [0:1] JJ -> 'lazy' *],\n",
      "    [Edge: [0:0] NP -> * JJ NNS],\n",
      "    [Edge: [0:1] NP -> JJ * NNS],\n",
      "    [Edge: [1:1] NNS -> * 'cats'],\n",
      "    [Edge: [1:2] NNS -> 'cats' *],\n",
      "    [Edge: [1:1] NP -> * NNS],\n",
      "    [Edge: [1:1] NNS -> * NNS CC NNS],\n",
      "    [Edge: [0:2] NP -> JJ NNS *],\n",
      "    [Edge: [1:2] NP -> NNS *],\n",
      "    [Edge: [1:2] NNS -> NNS * CC NNS],\n",
      "    [Edge: [1:1] S  -> * NP VP],\n",
      "    [Edge: [1:1] NP -> * NP CC NP],\n",
      "    [Edge: [1:2] S  -> NP * VP],\n",
      "    [Edge: [1:2] NP -> NP * CC NP],\n",
      "    [Edge: [0:0] S  -> * NP VP],\n",
      "    [Edge: [0:0] NP -> * NP CC NP],\n",
      "    [Edge: [0:2] S  -> NP * VP],\n",
      "    [Edge: [0:2] NP -> NP * CC NP],\n",
      "    [Edge: [2:2] VB -> * 'play'],\n",
      "    [Edge: [2:3] VB -> 'play' *],\n",
      "    [Edge: [2:2] VP -> * VB NNS],\n",
      "    [Edge: [2:3] VP -> VB * NNS],\n",
      "    [Edge: [3:3] IN -> * 'with'],\n",
      "    [Edge: [3:4] IN -> 'with' *],\n",
      "    [Edge: [3:3] NNS -> * IN NNS],\n",
      "    [Edge: [3:4] NNS -> IN * NNS],\n",
      "    [Edge: [4:4] NNS -> * 'mice'],\n",
      "    [Edge: [4:5] NNS -> 'mice' *],\n",
      "    [Edge: [4:4] NP -> * NNS],\n",
      "    [Edge: [4:4] NNS -> * NNS CC NNS],\n",
      "    [Edge: [3:5] NNS -> IN NNS *],\n",
      "    [Edge: [4:5] NP -> NNS *],\n",
      "    [Edge: [4:5] NNS -> NNS * CC NNS],\n",
      "    [Edge: [4:4] S  -> * NP VP],\n",
      "    [Edge: [4:4] NP -> * NP CC NP],\n",
      "    [Edge: [4:5] S  -> NP * VP],\n",
      "    [Edge: [4:5] NP -> NP * CC NP],\n",
      "    [Edge: [3:3] NP -> * NNS],\n",
      "    [Edge: [3:3] NNS -> * NNS CC NNS],\n",
      "    [Edge: [2:5] VP -> VB NNS *],\n",
      "    [Edge: [3:5] NP -> NNS *],\n",
      "    [Edge: [3:5] NNS -> NNS * CC NNS],\n",
      "    [Edge: [3:3] S  -> * NP VP],\n",
      "    [Edge: [3:3] NP -> * NP CC NP],\n",
      "    [Edge: [3:5] S  -> NP * VP],\n",
      "    [Edge: [3:5] NP -> NP * CC NP],\n",
      "    [Edge: [1:5] S  -> NP VP *],\n",
      "    [Edge: [0:5] S  -> NP VP *]]\n",
      "\n",
      "Parser:  <class 'nltk.parse.chart.BottomUpLeftCornerChartParser'>\n",
      "(S\n",
      "  (NP (JJ lazy) (NNS cats))\n",
      "  (VP (VB play) (NNS (IN with) (NNS mice))))\n",
      "               S                \n",
      "       ________|____             \n",
      "      |             VP          \n",
      "      |         ____|____        \n",
      "      NP       |        NNS     \n",
      "  ____|___     |     ____|___    \n",
      " JJ      NNS   VB   IN      NNS \n",
      " |        |    |    |        |   \n",
      "lazy     cats play with     mice\n",
      "\n",
      "number of trees: 1\n",
      "TD num edges =  32\n",
      "[   [Edge: [0:1] 'lazy'],\n",
      "    [Edge: [1:2] 'cats'],\n",
      "    [Edge: [2:3] 'play'],\n",
      "    [Edge: [3:4] 'with'],\n",
      "    [Edge: [4:5] 'mice'],\n",
      "    [Edge: [0:1] JJ -> 'lazy' *],\n",
      "    [Edge: [0:1] NP -> JJ * NNS],\n",
      "    [Edge: [1:2] NNS -> 'cats' *],\n",
      "    [Edge: [1:2] NP -> NNS *],\n",
      "    [Edge: [1:2] NNS -> NNS * CC NNS],\n",
      "    [Edge: [0:2] NP -> JJ NNS *],\n",
      "    [Edge: [0:2] S  -> NP * VP],\n",
      "    [Edge: [0:2] NP -> NP * CC NP],\n",
      "    [Edge: [1:2] S  -> NP * VP],\n",
      "    [Edge: [1:2] NP -> NP * CC NP],\n",
      "    [Edge: [2:3] VB -> 'play' *],\n",
      "    [Edge: [2:3] VP -> VB * NNS],\n",
      "    [Edge: [3:4] IN -> 'with' *],\n",
      "    [Edge: [3:4] NNS -> IN * NNS],\n",
      "    [Edge: [4:5] NNS -> 'mice' *],\n",
      "    [Edge: [4:5] NP -> NNS *],\n",
      "    [Edge: [4:5] NNS -> NNS * CC NNS],\n",
      "    [Edge: [3:5] NNS -> IN NNS *],\n",
      "    [Edge: [3:5] NP -> NNS *],\n",
      "    [Edge: [3:5] NNS -> NNS * CC NNS],\n",
      "    [Edge: [2:5] VP -> VB NNS *],\n",
      "    [Edge: [0:5] S  -> NP VP *],\n",
      "    [Edge: [1:5] S  -> NP VP *],\n",
      "    [Edge: [3:5] S  -> NP * VP],\n",
      "    [Edge: [3:5] NP -> NP * CC NP],\n",
      "    [Edge: [4:5] S  -> NP * VP],\n",
      "    [Edge: [4:5] NP -> NP * CC NP]]\n",
      "\n",
      "Parser:  <class 'nltk.parse.chart.LeftCornerChartParser'>\n",
      "(S\n",
      "  (NP (JJ lazy) (NNS cats))\n",
      "  (VP (VB play) (NNS (IN with) (NNS mice))))\n",
      "               S                \n",
      "       ________|____             \n",
      "      |             VP          \n",
      "      |         ____|____        \n",
      "      NP       |        NNS     \n",
      "  ____|___     |     ____|___    \n",
      " JJ      NNS   VB   IN      NNS \n",
      " |        |    |    |        |   \n",
      "lazy     cats play with     mice\n",
      "\n",
      "number of trees: 1\n",
      "TD num edges =  23\n",
      "[   [Edge: [0:1] 'lazy'],\n",
      "    [Edge: [1:2] 'cats'],\n",
      "    [Edge: [2:3] 'play'],\n",
      "    [Edge: [3:4] 'with'],\n",
      "    [Edge: [4:5] 'mice'],\n",
      "    [Edge: [0:1] JJ -> 'lazy' *],\n",
      "    [Edge: [0:1] NP -> JJ * NNS],\n",
      "    [Edge: [1:2] NNS -> 'cats' *],\n",
      "    [Edge: [1:2] NP -> NNS *],\n",
      "    [Edge: [0:2] NP -> JJ NNS *],\n",
      "    [Edge: [0:2] S  -> NP * VP],\n",
      "    [Edge: [1:2] S  -> NP * VP],\n",
      "    [Edge: [2:3] VB -> 'play' *],\n",
      "    [Edge: [2:3] VP -> VB * NNS],\n",
      "    [Edge: [3:4] IN -> 'with' *],\n",
      "    [Edge: [3:4] NNS -> IN * NNS],\n",
      "    [Edge: [4:5] NNS -> 'mice' *],\n",
      "    [Edge: [4:5] NP -> NNS *],\n",
      "    [Edge: [3:5] NNS -> IN NNS *],\n",
      "    [Edge: [3:5] NP -> NNS *],\n",
      "    [Edge: [2:5] VP -> VB NNS *],\n",
      "    [Edge: [0:5] S  -> NP VP *],\n",
      "    [Edge: [1:5] S  -> NP VP *]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# MANDATORY 1\n",
    "\n",
    "import nltk\n",
    "from nltk import CFG, ChartParser, BottomUpChartParser, BottomUpLeftCornerChartParser, LeftCornerChartParser\n",
    "\n",
    "grammar = CFG.fromstring('''\n",
    "S -> NP VP\n",
    "NP -> NNS | JJ NNS | NP CC NP \n",
    "VP -> VB NNS\n",
    "NNS -> \"cats\" | \"dogs\" | \"mice\" | NNS CC NNS | IN NNS\n",
    "JJ -> \"big\" | \"small\" | \"lazy\"\n",
    "CC -> \"and\" | \"or\"\n",
    "VB -> \"play\"\n",
    "IN -> \"with\"\n",
    "''')\n",
    "\n",
    "sent = ['lazy', 'cats', 'play', 'with', 'mice']\n",
    "parsers = [ChartParser, BottomUpChartParser, BottomUpLeftCornerChartParser, LeftCornerChartParser]\n",
    "\n",
    "for parser in parsers:\n",
    "    print('Parser: ', parser)\n",
    "    parse(parser, grammar, sent)\n",
    "    print('')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most efficient parser for this case was the LeftCornerChartParser as it was able to calculate the chart with least amount of edges.\n",
    "\n",
    "The edges filtered out by the BottomUpLeftCornerChartParser are the ones without any word subsumption, for example [Edge: [0:0] NP -> * JJ NNS] or edge [Edge: [1:1] NNS -> * 'cats'], which are edges that are present in the BottomUpChartParser, but not in this parser, because they are not generalizing. \n",
    "\n",
    "Then, the edges filtered out by the LeftCornerChartParser are the subsumptions that are already present, so basically any edges with CCs are filtered out since they are present in other edges. For example: [Edge: [1:2] NNS -> NNS * CC NNS] is filtered out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package sentiwordnet to\n",
      "[nltk_data]     /home/santiago/nltk_data...\n",
      "[nltk_data]   Package sentiwordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('sentiwordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word distances: [0.6923076923076923, 0.7368421052631579, 0.6666666666666666, 0.5454545454545454, 0.7692307692307693, 0.8620689655172413]\n",
      "Lemmatized distances: [0.6923076923076923, 0.6666666666666666, 0.6666666666666666, 0.5454545454545454, 0.7692307692307693, 0.8620689655172413]\n",
      "Lesk distances: [0.7, 0.7857142857142857, 0.5, 0.8888888888888888, 0.9, 0.92]\n",
      "Lesk variant with hypernyms distances: [0.7, 0.8, 0.4444444444444444, 0.8333333333333334, 0.875, 0.9]\n",
      "CoreNLP dependency parser distances: [1.0, 0.8823529411764706, 0.9411764705882353, 0.5714285714285714, 1.0, 0.9655172413793104]\n",
      "\n",
      "Words correlation: 0.4143770872333895\n",
      "Lemmatized words correlation: 0.517276212426234\n",
      "Lesk correlation: 0.6056964784272112\n",
      "Lesk variant with hypernyms correlation: 0.5101560894527944\n",
      "CoreNLP dependency parser correlation: -0.06178309306886861\n"
     ]
    }
   ],
   "source": [
    "# MANDATORY 2\n",
    "import nltk\n",
    "from nltk.wsd import lesk\n",
    "from nltk import pos_tag\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.metrics import jaccard_distance\n",
    "from nltk.corpus import wordnet as wn \n",
    "from nltk.parse.corenlp import CoreNLPDependencyParser\n",
    "from scipy.stats import pearsonr\n",
    "  \n",
    "def lemmatize(p):\n",
    "    if p[1][0] in {'N', 'V'}:\n",
    "        return wnl.lemmatize(p[0].lower(), pos=p[1][0].lower())\n",
    "    return p[0]\n",
    "\n",
    "def penn2morphy(penntag, returnNone=False):\n",
    "    morphy_tag = {'NN':wn.NOUN, 'JJ':wn.ADJ,\n",
    "                  'VB':wn.VERB, 'RB':wn.ADV}\n",
    "    try:\n",
    "        return morphy_tag[penntag[:2]]\n",
    "    except:\n",
    "        return None if returnNone else ''\n",
    "\n",
    "def getHypernym(s):\n",
    "    if not s:\n",
    "        return [s]\n",
    "    if s.hypernyms() == []:\n",
    "        return [None]\n",
    "    return s.hypernyms()\n",
    "\n",
    "def parseWithCoreNLP(s):\n",
    "    # res = []\n",
    "    # tree = next(parser.raw_parse(s))\n",
    "    # for t in tree.triples():\n",
    "    #     res.append(tuple([x[0] for x in t if isinstance(x, tuple)]))\n",
    "    # return res\n",
    "    res = []\n",
    "    tree = next(parser.raw_parse(s))\n",
    "    for t in tree.triples():\n",
    "        res.append(tuple([lesk(s, x[0], pos=penn2morphy(x[1][0])) for x in t if isinstance(x, tuple)]))\n",
    "    return res\n",
    "\n",
    "wnl = WordNetLemmatizer()\n",
    "parser = CoreNLPDependencyParser(url='http://localhost:9000')\n",
    "\n",
    "input_file = 'trial/STS.input.txt'\n",
    "with open(input_file) as f:\n",
    "    input_data = f.readlines()\n",
    "    \n",
    "document_distances = []\n",
    "lesks_distances = []\n",
    "lesks_hyper_distances = []\n",
    "morphology_distances = []\n",
    "corenlp_distances = []\n",
    "for i in input_data:\n",
    "    sentences = nltk.sent_tokenize(i[4:])\n",
    "    words = [nltk.word_tokenize(sent) for sent in sentences]\n",
    "    pairs = [pos_tag(w) for w in words]\n",
    "    l_words = [[lemmatize(p) for p in pair] for pair in pairs]\n",
    "    synsets = [[[lesk(w, p[0], pos=penn2morphy(p[1][0])) for p in pair] for pair in pairs] for w in words]\n",
    "    hypernyms = [[getHypernym(s) for s in synsets[c][c]] for c in range(len(synsets))]\n",
    "    hypernyms = [[hy[0] for hy in hyp] for hyp in hypernyms]\n",
    "    corenlp = [parseWithCoreNLP(s) for s in sentences]\n",
    "    lesks_distances.append(jaccard_distance(set(synsets[0][0]), set(synsets[1][1])))\n",
    "    morphology_distances.append(jaccard_distance(set(l_words[0]),set(l_words[1])))\n",
    "    document_distances.append(jaccard_distance(set(words[0]),set(words[1])))\n",
    "    lesks_hyper_distances.append(jaccard_distance(set(hypernyms[0]),set(hypernyms[1])))\n",
    "    corenlp_distances.append(jaccard_distance(set(corenlp[0]),set(corenlp[1])))\n",
    "            \n",
    "            \n",
    "    \n",
    "print(\"Word distances: \" + str(document_distances))\n",
    "print(\"Lemmatized distances: \" + str(morphology_distances))\n",
    "print(\"Lesk distances: \" + str(lesks_distances))\n",
    "print(\"Lesk variant with hypernyms distances: \" + str(lesks_hyper_distances))\n",
    "print(\"CoreNLP dependency parser distances: \" + str(corenlp_distances))\n",
    "print(\"\")\n",
    "\n",
    "gold_file = 'trial/STS.gs.txt'\n",
    "with open(gold_file) as f:\n",
    "    gold_data = f.readlines()\n",
    "gold = [int(g[4:5]) for g in gold_data]\n",
    "\n",
    "doc_pearson = pearsonr(document_distances, gold)[0]\n",
    "mor_pearson = pearsonr(morphology_distances, gold)[0]\n",
    "lesk_pearson = pearsonr(lesks_distances, gold)[0]\n",
    "hypernyms_pearson = pearsonr(lesks_hyper_distances, gold)[0]\n",
    "corenlp_pearson = pearsonr(corenlp_distances, gold)[0]\n",
    "\n",
    "print('Words correlation: ' + str(doc_pearson))\n",
    "print('Lemmatized words correlation: ' + str(mor_pearson))\n",
    "print('Lesk correlation: ' + str(lesk_pearson))\n",
    "print('Lesk variant with hypernyms correlation: ' + str(hypernyms_pearson))\n",
    "print(\"CoreNLP dependency parser correlation: \" + str(corenlp_pearson))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is awful compared to the previous strategies. We tried to calculate the synsets of the words and the result improved a little bit. That might be because it is more difficult to find similarities between the pairs since they are less common than the simple words. Using the same reasoning, we don't think that using NEs would help the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'id1\\tThe bird is bathing in the sink.\\tBirdie is washing itself in the water basin.\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
