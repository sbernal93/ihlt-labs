{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "\n",
    "def parse(parser, grammar, sent):\n",
    "    parser = parser(grammar)\n",
    "    parse = parser.parse(sent)\n",
    "    ts = []\n",
    "    for t in parse:\n",
    "        ts.append(t)\n",
    "        print(t)\n",
    "        t.pretty_print()\n",
    "    print('number of trees:', len(ts))\n",
    "    parse = parser.chart_parse(['small', 'cats', 'and', 'mice'])\n",
    "    print(\"TD num edges = \", parse.num_edges())\n",
    "    pp.pprint(parse.edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parser:  <class 'nltk.parse.chart.ChartParser'>\n",
      "(S\n",
      "  (NP (JJ lazy) (NNS cats))\n",
      "  (VP (VB play) (NNS (IN with) (NNS mice))))\n",
      "               S                \n",
      "       ________|____             \n",
      "      |             VP          \n",
      "      |         ____|____        \n",
      "      NP       |        NNS     \n",
      "  ____|___     |     ____|___    \n",
      " JJ      NNS   VB   IN      NNS \n",
      " |        |    |    |        |   \n",
      "lazy     cats play with     mice\n",
      "\n",
      "number of trees: 1\n",
      "TD num edges =  33\n",
      "[   [Edge: [0:1] 'small'],\n",
      "    [Edge: [1:2] 'cats'],\n",
      "    [Edge: [2:3] 'and'],\n",
      "    [Edge: [3:4] 'mice'],\n",
      "    [Edge: [0:1] JJ -> 'small' *],\n",
      "    [Edge: [0:1] NP -> JJ * NNS],\n",
      "    [Edge: [1:2] NNS -> 'cats' *],\n",
      "    [Edge: [1:2] NP -> NNS *],\n",
      "    [Edge: [1:2] NNS -> NNS * CC NNS],\n",
      "    [Edge: [0:2] NP -> JJ NNS *],\n",
      "    [Edge: [0:2] S  -> NP * VP],\n",
      "    [Edge: [0:2] NP -> NP * CC NP],\n",
      "    [Edge: [1:2] S  -> NP * VP],\n",
      "    [Edge: [1:2] NP -> NP * CC NP],\n",
      "    [Edge: [2:3] CC -> 'and' *],\n",
      "    [Edge: [1:3] NNS -> NNS CC * NNS],\n",
      "    [Edge: [0:3] NP -> NP CC * NP],\n",
      "    [Edge: [1:3] NP -> NP CC * NP],\n",
      "    [Edge: [3:4] NNS -> 'mice' *],\n",
      "    [Edge: [3:4] NP -> NNS *],\n",
      "    [Edge: [3:4] NNS -> NNS * CC NNS],\n",
      "    [Edge: [1:4] NNS -> NNS CC NNS *],\n",
      "    [Edge: [1:4] NP -> NNS *],\n",
      "    [Edge: [1:4] NNS -> NNS * CC NNS],\n",
      "    [Edge: [0:4] NP -> JJ NNS *],\n",
      "    [Edge: [0:4] S  -> NP * VP],\n",
      "    [Edge: [0:4] NP -> NP * CC NP],\n",
      "    [Edge: [1:4] S  -> NP * VP],\n",
      "    [Edge: [1:4] NP -> NP * CC NP],\n",
      "    [Edge: [3:4] S  -> NP * VP],\n",
      "    [Edge: [3:4] NP -> NP * CC NP],\n",
      "    [Edge: [0:4] NP -> NP CC NP *],\n",
      "    [Edge: [1:4] NP -> NP CC NP *]]\n",
      "\n",
      "Parser:  <class 'nltk.parse.chart.BottomUpChartParser'>\n",
      "(S\n",
      "  (NP (JJ lazy) (NNS cats))\n",
      "  (VP (VB play) (NNS (IN with) (NNS mice))))\n",
      "               S                \n",
      "       ________|____             \n",
      "      |             VP          \n",
      "      |         ____|____        \n",
      "      NP       |        NNS     \n",
      "  ____|___     |     ____|___    \n",
      " JJ      NNS   VB   IN      NNS \n",
      " |        |    |    |        |   \n",
      "lazy     cats play with     mice\n",
      "\n",
      "number of trees: 1\n",
      "TD num edges =  48\n",
      "[   [Edge: [0:1] 'small'],\n",
      "    [Edge: [1:2] 'cats'],\n",
      "    [Edge: [2:3] 'and'],\n",
      "    [Edge: [3:4] 'mice'],\n",
      "    [Edge: [0:0] JJ -> * 'small'],\n",
      "    [Edge: [0:1] JJ -> 'small' *],\n",
      "    [Edge: [0:0] NP -> * JJ NNS],\n",
      "    [Edge: [0:1] NP -> JJ * NNS],\n",
      "    [Edge: [1:1] NNS -> * 'cats'],\n",
      "    [Edge: [1:2] NNS -> 'cats' *],\n",
      "    [Edge: [1:1] NP -> * NNS],\n",
      "    [Edge: [1:1] NNS -> * NNS CC NNS],\n",
      "    [Edge: [0:2] NP -> JJ NNS *],\n",
      "    [Edge: [1:2] NP -> NNS *],\n",
      "    [Edge: [1:2] NNS -> NNS * CC NNS],\n",
      "    [Edge: [1:1] S  -> * NP VP],\n",
      "    [Edge: [1:1] NP -> * NP CC NP],\n",
      "    [Edge: [1:2] S  -> NP * VP],\n",
      "    [Edge: [1:2] NP -> NP * CC NP],\n",
      "    [Edge: [0:0] S  -> * NP VP],\n",
      "    [Edge: [0:0] NP -> * NP CC NP],\n",
      "    [Edge: [0:2] S  -> NP * VP],\n",
      "    [Edge: [0:2] NP -> NP * CC NP],\n",
      "    [Edge: [2:2] CC -> * 'and'],\n",
      "    [Edge: [2:3] CC -> 'and' *],\n",
      "    [Edge: [1:3] NNS -> NNS CC * NNS],\n",
      "    [Edge: [1:3] NP -> NP CC * NP],\n",
      "    [Edge: [0:3] NP -> NP CC * NP],\n",
      "    [Edge: [3:3] NNS -> * 'mice'],\n",
      "    [Edge: [3:4] NNS -> 'mice' *],\n",
      "    [Edge: [3:3] NP -> * NNS],\n",
      "    [Edge: [3:3] NNS -> * NNS CC NNS],\n",
      "    [Edge: [1:4] NNS -> NNS CC NNS *],\n",
      "    [Edge: [3:4] NP -> NNS *],\n",
      "    [Edge: [3:4] NNS -> NNS * CC NNS],\n",
      "    [Edge: [3:3] S  -> * NP VP],\n",
      "    [Edge: [3:3] NP -> * NP CC NP],\n",
      "    [Edge: [1:4] NP -> NP CC NP *],\n",
      "    [Edge: [0:4] NP -> NP CC NP *],\n",
      "    [Edge: [3:4] S  -> NP * VP],\n",
      "    [Edge: [3:4] NP -> NP * CC NP],\n",
      "    [Edge: [0:4] S  -> NP * VP],\n",
      "    [Edge: [0:4] NP -> NP * CC NP],\n",
      "    [Edge: [1:4] S  -> NP * VP],\n",
      "    [Edge: [1:4] NP -> NP * CC NP],\n",
      "    [Edge: [0:4] NP -> JJ NNS *],\n",
      "    [Edge: [1:4] NP -> NNS *],\n",
      "    [Edge: [1:4] NNS -> NNS * CC NNS]]\n",
      "\n",
      "Parser:  <class 'nltk.parse.chart.BottomUpLeftCornerChartParser'>\n",
      "(S\n",
      "  (NP (JJ lazy) (NNS cats))\n",
      "  (VP (VB play) (NNS (IN with) (NNS mice))))\n",
      "               S                \n",
      "       ________|____             \n",
      "      |             VP          \n",
      "      |         ____|____        \n",
      "      NP       |        NNS     \n",
      "  ____|___     |     ____|___    \n",
      " JJ      NNS   VB   IN      NNS \n",
      " |        |    |    |        |   \n",
      "lazy     cats play with     mice\n",
      "\n",
      "number of trees: 1\n",
      "TD num edges =  33\n",
      "[   [Edge: [0:1] 'small'],\n",
      "    [Edge: [1:2] 'cats'],\n",
      "    [Edge: [2:3] 'and'],\n",
      "    [Edge: [3:4] 'mice'],\n",
      "    [Edge: [0:1] JJ -> 'small' *],\n",
      "    [Edge: [0:1] NP -> JJ * NNS],\n",
      "    [Edge: [1:2] NNS -> 'cats' *],\n",
      "    [Edge: [1:2] NP -> NNS *],\n",
      "    [Edge: [1:2] NNS -> NNS * CC NNS],\n",
      "    [Edge: [0:2] NP -> JJ NNS *],\n",
      "    [Edge: [0:2] S  -> NP * VP],\n",
      "    [Edge: [0:2] NP -> NP * CC NP],\n",
      "    [Edge: [1:2] S  -> NP * VP],\n",
      "    [Edge: [1:2] NP -> NP * CC NP],\n",
      "    [Edge: [2:3] CC -> 'and' *],\n",
      "    [Edge: [1:3] NNS -> NNS CC * NNS],\n",
      "    [Edge: [0:3] NP -> NP CC * NP],\n",
      "    [Edge: [1:3] NP -> NP CC * NP],\n",
      "    [Edge: [3:4] NNS -> 'mice' *],\n",
      "    [Edge: [3:4] NP -> NNS *],\n",
      "    [Edge: [3:4] NNS -> NNS * CC NNS],\n",
      "    [Edge: [1:4] NNS -> NNS CC NNS *],\n",
      "    [Edge: [1:4] NP -> NNS *],\n",
      "    [Edge: [1:4] NNS -> NNS * CC NNS],\n",
      "    [Edge: [0:4] NP -> JJ NNS *],\n",
      "    [Edge: [0:4] S  -> NP * VP],\n",
      "    [Edge: [0:4] NP -> NP * CC NP],\n",
      "    [Edge: [1:4] S  -> NP * VP],\n",
      "    [Edge: [1:4] NP -> NP * CC NP],\n",
      "    [Edge: [3:4] S  -> NP * VP],\n",
      "    [Edge: [3:4] NP -> NP * CC NP],\n",
      "    [Edge: [0:4] NP -> NP CC NP *],\n",
      "    [Edge: [1:4] NP -> NP CC NP *]]\n",
      "\n",
      "Parser:  <class 'nltk.parse.chart.LeftCornerChartParser'>\n",
      "(S\n",
      "  (NP (JJ lazy) (NNS cats))\n",
      "  (VP (VB play) (NNS (IN with) (NNS mice))))\n",
      "               S                \n",
      "       ________|____             \n",
      "      |             VP          \n",
      "      |         ____|____        \n",
      "      NP       |        NNS     \n",
      "  ____|___     |     ____|___    \n",
      " JJ      NNS   VB   IN      NNS \n",
      " |        |    |    |        |   \n",
      "lazy     cats play with     mice\n",
      "\n",
      "number of trees: 1\n",
      "TD num edges =  23\n",
      "[   [Edge: [0:1] 'small'],\n",
      "    [Edge: [1:2] 'cats'],\n",
      "    [Edge: [2:3] 'and'],\n",
      "    [Edge: [3:4] 'mice'],\n",
      "    [Edge: [0:1] JJ -> 'small' *],\n",
      "    [Edge: [0:1] NP -> JJ * NNS],\n",
      "    [Edge: [1:2] NNS -> 'cats' *],\n",
      "    [Edge: [1:2] NP -> NNS *],\n",
      "    [Edge: [1:2] NNS -> NNS * CC NNS],\n",
      "    [Edge: [0:2] NP -> JJ NNS *],\n",
      "    [Edge: [0:2] NP -> NP * CC NP],\n",
      "    [Edge: [1:2] NP -> NP * CC NP],\n",
      "    [Edge: [2:3] CC -> 'and' *],\n",
      "    [Edge: [1:3] NNS -> NNS CC * NNS],\n",
      "    [Edge: [0:3] NP -> NP CC * NP],\n",
      "    [Edge: [1:3] NP -> NP CC * NP],\n",
      "    [Edge: [3:4] NNS -> 'mice' *],\n",
      "    [Edge: [3:4] NP -> NNS *],\n",
      "    [Edge: [1:4] NNS -> NNS CC NNS *],\n",
      "    [Edge: [1:4] NP -> NNS *],\n",
      "    [Edge: [0:4] NP -> JJ NNS *],\n",
      "    [Edge: [0:4] NP -> NP CC NP *],\n",
      "    [Edge: [1:4] NP -> NP CC NP *]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk import CFG, ChartParser, BottomUpChartParser, BottomUpLeftCornerChartParser, LeftCornerChartParser\n",
    "\n",
    "grammar = CFG.fromstring('''\n",
    "S -> NP VP\n",
    "NP -> NNS | JJ NNS | NP CC NP \n",
    "VP -> VB NNS\n",
    "NNS -> \"cats\" | \"dogs\" | \"mice\" | NNS CC NNS | IN NNS\n",
    "JJ -> \"big\" | \"small\" | \"lazy\"\n",
    "CC -> \"and\" | \"or\"\n",
    "VB -> \"play\"\n",
    "IN -> \"with\"\n",
    "''')\n",
    "\n",
    "sent = ['lazy', 'cats', 'play', 'with', 'mice']\n",
    "parsers = [ChartParser, BottomUpChartParser, BottomUpLeftCornerChartParser, LeftCornerChartParser]\n",
    "\n",
    "for parser in parsers:\n",
    "    print('Parser: ', parser)\n",
    "    parse(parser, grammar, sent)\n",
    "    print('')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lab2 distances: [0.6923076923076923, 0.7368421052631579, 0.6666666666666666, 0.5454545454545454, 0.7692307692307693, 0.8620689655172413]\n",
      "Lab3 distances: [0.6923076923076923, 0.6666666666666666, 0.6666666666666666, 0.5454545454545454, 0.7692307692307693, 0.8620689655172413]\n",
      "Lesk distance: [0.7, 0.7857142857142857, 0.5, 0.8888888888888888, 0.9, 0.92]\n",
      "Words and NE distance:[0.6923076923076923, 0.7368421052631579, 0.6666666666666666, 0.5454545454545454, 0.7692307692307693, 0.8620689655172413]\n",
      "CoreNLP parser distance:[1.0, 1.0, 0.9444444444444444, 0.6, 1.0, 0.9666666666666667]\n"
     ]
    }
   ],
   "source": [
    "from nltk import word_tokenize, pos_tag, ne_chunk\n",
    "from nltk.wsd import lesk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.metrics import jaccard_distance\n",
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "def lemmatize(p):\n",
    "    if p[1][0] in {'N', 'V'}:\n",
    "        return wnl.lemmatize(p[0].lower(), pos=p[1][0].lower())\n",
    "    return p[0]\n",
    "\n",
    "def penn2morphy(penntag, returnNone=False):\n",
    "    morphy_tag = {'NN':wn.NOUN, 'JJ':wn.ADJ,\n",
    "                  'VB':wn.VERB, 'RB':wn.ADV}\n",
    "    try:\n",
    "        return morphy_tag[penntag[:2]]\n",
    "    except:\n",
    "        return None if returnNone else ''\n",
    "    \n",
    "def words_and_ne(nerc):\n",
    "    if(isinstance(nerc,nltk.Tree)):\n",
    "        return ' '.join([r[0] for r in nerc.leaves()])\n",
    "    return nerc[0]\n",
    "        \n",
    "def getvalue(triple):\n",
    "    value = triple[0][0], triple[1], triple[2][0]\n",
    "    return value\n",
    "    \n",
    "wnl = WordNetLemmatizer()\n",
    "\n",
    "input_file = 'trial/STS.input.txt'\n",
    "with open(input_file) as f:\n",
    "    input_data = f.readlines()\n",
    "    \n",
    "document_distances = []\n",
    "lesks_distances = []\n",
    "morphology_distances = []\n",
    "wordsne_distances = []\n",
    "corenlp_distances = []\n",
    "for i in input_data:\n",
    "    sentences = nltk.sent_tokenize(i[4:])\n",
    "    words = [nltk.word_tokenize(sent) for sent in sentences]\n",
    "    pairs = [pos_tag(w) for w in words]\n",
    "    l_words = [[lemmatize(p) for p in pair] for pair in pairs]\n",
    "    res = [ne_chunk(p, binary=True) for p in pairs]\n",
    "    wordsne = [[words_and_ne(r) for r in ress] for ress in res]\n",
    "    synsets = [[[lesk(w, p[0], pos=penn2morphy(p[1][0])) for p in pair] for pair in pairs] for w in words]\n",
    "    \n",
    "    #CoreNLP\n",
    "    parsed = [parser.raw_parse(sent) for sent in sentences]\n",
    "    triples = [[t for t in next(par).triples()] for par in parsed]\n",
    "    corenlp = [[getvalue(tri) for tri in triple ]for triple in triples]\n",
    "    \n",
    "    lesks_distances.append(jaccard_distance(set(synsets[0][0]), set(synsets[1][1])))\n",
    "    morphology_distances.append(jaccard_distance(set(l_words[0]),set(l_words[1])))\n",
    "    document_distances.append(jaccard_distance(set(words[0]),set(words[1])))\n",
    "    wordsne_distances.append(jaccard_distance(set(wordsne[0]), set(wordsne[1])))\n",
    "    corenlp_distances.append(jaccard_distance(set(corenlp[0]), set(corenlp[1])))\n",
    "    \n",
    "    \n",
    "    \n",
    "print(\"Lab2 distances: \" + str(document_distances))\n",
    "print(\"Lab3 distances: \" + str(morphology_distances))\n",
    "print(\"Lesk distance: \" + str(lesks_distances))\n",
    "print('Words and NE distance:' + str(wordsne_distances))\n",
    "print('CoreNLP parser distance:' + str(corenlp_distances))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lab2 pearson correlation: 0.4143770872333895\n",
      "Lab3 pearson correlation: 0.517276212426234\n",
      "Lesk pearson correlation: 0.6056964784272112\n",
      "Words and NE pearson correlation: 0.4143770872333895\n",
      "CoreNLP parser pearson correlation: -0.17322964246636668\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import pearsonr\n",
    "\n",
    "gold_file = 'trial/STS.gs.txt'\n",
    "with open(gold_file) as f:\n",
    "    gold_data = f.readlines()\n",
    "gold = [int(g[4:5]) for g in gold_data]\n",
    "\n",
    "doc_pearson = pearsonr(document_distances, gold)[0]\n",
    "mor_pearson = pearsonr(morphology_distances, gold)[0]\n",
    "lesk_pearson = pearsonr(lesks_distances, gold)[0]\n",
    "wordsne_pearson = pearsonr(wordsne_distances, gold)[0]\n",
    "corenlp_pearson = pearsonr(corenlp_distances, gold)[0]\n",
    "\n",
    "print('Lab2 pearson correlation: ' + str(doc_pearson))\n",
    "print('Lab3 pearson correlation: ' + str(mor_pearson))\n",
    "print('Lesk pearson correlation: ' + str(lesk_pearson))\n",
    "print('Words and NE pearson correlation: ' + str(wordsne_pearson))\n",
    "print('CoreNLP parser pearson correlation: ' + str(corenlp_pearson))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('jumps', 'VBZ'), 'nsubj', ('Smith', 'NNP'))\n",
      "(('jumps', 'VBZ'), 'nmod', ('dog', 'NN'))\n",
      "(('dog', 'NN'), 'case', ('over', 'IN'))\n",
      "(('dog', 'NN'), 'det', ('the', 'DT'))\n",
      "(('dog', 'NN'), 'amod', ('lazy', 'JJ'))\n"
     ]
    }
   ],
   "source": [
    "from nltk.parse.corenlp import CoreNLPDependencyParser\n",
    "\n",
    "parser = CoreNLPDependencyParser(url='http://localhost:9000')\n",
    "parse = parser.raw_parse('Smith jumps over the lazy dog')\n",
    "\n",
    "tree = next(parse)\n",
    "for t in tree.triples():\n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(('went', 'VBD'), 'nsubj', ('John', 'NNP')), (('went', 'VBD'), 'dobj', ('horse', 'NN')), (('went', 'VBD'), 'xcomp', ('riding', 'VBG')), (('riding', 'VBG'), 'advmod', ('back', 'RB')), (('riding', 'VBG'), 'nmod', ('dawn', 'NN')), (('dawn', 'NN'), 'case', ('at', 'IN')), (('riding', 'VBG'), 'nmod', ('group', 'NN')), (('group', 'NN'), 'case', ('with', 'IN')), (('group', 'NN'), 'det', ('a', 'DT')), (('group', 'NN'), 'amod', ('whole', 'JJ')), (('group', 'NN'), 'nmod', ('friends', 'NNS')), (('friends', 'NNS'), 'case', ('of', 'IN')), (('went', 'VBD'), 'punct', ('.', '.'))], [(('view', 'NN'), 'nsubj', ('Sunrise', 'NNP')), (('Sunrise', 'NNP'), 'nmod', ('dawn', 'NN')), (('dawn', 'NN'), 'case', ('at', 'IN')), (('view', 'NN'), 'cop', ('is', 'VBZ')), (('view', 'NN'), 'det', ('a', 'DT')), (('view', 'NN'), 'amod', ('magnificent', 'JJ')), (('view', 'NN'), 'acl', ('take', 'VB')), (('take', 'VB'), 'mark', ('to', 'TO')), (('take', 'VB'), 'compound:prt', ('in', 'RP')), (('take', 'VB'), 'advcl', ('wake', 'VBP')), (('wake', 'VBP'), 'mark', ('if', 'IN')), (('wake', 'VBP'), 'nsubj', ('you', 'PRP')), (('wake', 'VBP'), 'advmod', ('up', 'RB')), (('wake', 'VBP'), 'advmod', ('enough', 'JJ')), (('enough', 'JJ'), 'advmod', ('early', 'RB')), (('enough', 'JJ'), 'nmod', ('it', 'PRP')), (('it', 'PRP'), 'case', ('for', 'IN')), (('view', 'NN'), 'punct', ('.', '.'))]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "input_file = 'trial/STS.input.txt'\n",
    "with open(input_file) as f:\n",
    "    input_data = f.readlines()\n",
    "    \n",
    "for i in input_data:\n",
    "    sentences = nltk.sent_tokenize(i[4:])\n",
    "    parsed = [parser.raw_parse(sent) for sent in sentences]\n",
    "    triples = [[t for t in next(par).triples()] for par in parsed]\n",
    "    \n",
    "\n",
    "print(triples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('went', 'nsubj', 'John'),\n",
       "  ('went', 'dobj', 'horse'),\n",
       "  ('went', 'xcomp', 'riding'),\n",
       "  ('riding', 'advmod', 'back'),\n",
       "  ('riding', 'nmod', 'dawn'),\n",
       "  ('dawn', 'case', 'at'),\n",
       "  ('riding', 'nmod', 'group'),\n",
       "  ('group', 'case', 'with'),\n",
       "  ('group', 'det', 'a'),\n",
       "  ('group', 'amod', 'whole'),\n",
       "  ('group', 'nmod', 'friends'),\n",
       "  ('friends', 'case', 'of'),\n",
       "  ('went', 'punct', '.')],\n",
       " [('view', 'nsubj', 'Sunrise'),\n",
       "  ('Sunrise', 'nmod', 'dawn'),\n",
       "  ('dawn', 'case', 'at'),\n",
       "  ('view', 'cop', 'is'),\n",
       "  ('view', 'det', 'a'),\n",
       "  ('view', 'amod', 'magnificent'),\n",
       "  ('view', 'acl', 'take'),\n",
       "  ('take', 'mark', 'to'),\n",
       "  ('take', 'compound:prt', 'in'),\n",
       "  ('take', 'advcl', 'wake'),\n",
       "  ('wake', 'mark', 'if'),\n",
       "  ('wake', 'nsubj', 'you'),\n",
       "  ('wake', 'advmod', 'up'),\n",
       "  ('wake', 'advmod', 'enough'),\n",
       "  ('enough', 'advmod', 'early'),\n",
       "  ('enough', 'nmod', 'it'),\n",
       "  ('it', 'case', 'for'),\n",
       "  ('view', 'punct', '.')]]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def getvalue(triple):\n",
    "    value = triple[0][0], triple[1], triple[2][0]\n",
    "    return value\n",
    "\n",
    "cons = [[getvalue(tri) for tri in triple ]for triple in triples]\n",
    "\n",
    "cons\n",
    "#jaccard_distance(set(cons[0]), set(cons[1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
